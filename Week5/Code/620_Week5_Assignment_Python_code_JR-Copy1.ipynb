{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "title_df = pd.DataFrame()\n",
    "location_df = pd.DataFrame()\n",
    "company_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "URL = \"https://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "def writeToJSONFile(path, fileName, data):\n",
    "    filePathNameWExt = path + '/' + fileName + '.json'\n",
    "    with open(filePathNameWExt, 'w') as fp:\n",
    "        json.dump(data, fp)\n",
    "        \n",
    "def extract_location_from_result(soup): \n",
    "  locations = []\n",
    "  spans = soup.findAll(\"div\", attrs={\"class\": \"location\"})\n",
    "  for span in spans:\n",
    "        locations.append(span.text)\n",
    "  return(locations)\n",
    "\n",
    "\n",
    "def extract_summary_from_result(soup): \n",
    "  summaries = []\n",
    "  spans = soup.findAll('span', attrs={'class': 'summary'})\n",
    "  for span in spans:\n",
    "    summaries.append(span.text.strip())\n",
    "  return(summaries)\n",
    "\n",
    "\n",
    "def extract_company_from_result(soup): \n",
    "  companies = []\n",
    "  for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "    company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
    "    for b in company:\n",
    "     companies.append(b.text.strip())\n",
    "  return(companies)\n",
    "\n",
    "\n",
    "def extract_job_title_from_result(soup): \n",
    "  jobs = []\n",
    "  for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "      for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "          jobs.append(a[\"title\"])\n",
    "  return(jobs)\n",
    "\n",
    "def extract_df_from_URL(URL,title_df,location_df,company_df): \n",
    "  page = requests.get(URL)\n",
    "  soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "  title = extract_job_title_from_result(soup)\n",
    "  location = extract_location_from_result(soup)\n",
    "  company = extract_company_from_result(soup)\n",
    "  title_df.append(pd.DataFrame(title))\n",
    "  location_df.append(pd.DataFrame(location))\n",
    "  company_df.append(pd.DataFrame(company))\n",
    "\n",
    "title = []\n",
    "location = []\n",
    "summary = []\n",
    "company = []\n",
    "\n",
    "title_df = pd.DataFrame()\n",
    "location_df = pd.DataFrame()\n",
    "company_df = pd.DataFrame()\n",
    "\n",
    "for i in range(2,3):\n",
    "    URL = \"https://www.indeed.com/jobs?q=data+scientist&l=all&start=\"+str(i)\n",
    "    extract_df_from_URL(URL,title_df,location_df,company_df)\n",
    "\n",
    "json_title = title_df.to_json(orient='records')\n",
    "json_location = location_df.to_json(orient='records')\n",
    "json_company = company_df.to_json(orient='records')\n",
    "\n",
    "\n",
    "\n",
    "writeToJSONFile('./','title',json_title)\n",
    "writeToJSONFile('./','location',json_location)\n",
    "writeToJSONFile('./','company',json_company)\n",
    "\n",
    "print(\"JSON Export Complete\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
